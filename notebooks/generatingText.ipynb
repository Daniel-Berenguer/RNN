{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67655f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../int_to_chars\", \"rb\") as file:\n",
    "    int_to_chars = pickle.load(file)\n",
    "\n",
    "chars_to_int = dict()\n",
    "for i in range(len(int_to_chars)):\n",
    "    chars_to_int[int_to_chars[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6af9f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the root directory to the system path\n",
    "root_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "\n",
    "from src.model import Model\n",
    "\n",
    "\n",
    "HSIZE = 128\n",
    "\n",
    "model = Model(len(int_to_chars), HSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ab2690",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../model_weights\", \"rb\") as file:\n",
    "    model.load_state_dict(torch.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab84a9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-2.0621,  2.4257, -1.6067, -2.5220, -0.9118,  3.7980, -2.7124, -2.8190,\n",
      "        -0.6342, -0.3087,  2.8725, -0.5868, -1.7704,  1.7434,  0.5291, -0.0644,\n",
      "         3.7296, -0.9913,  0.6398, -1.5069,  3.4801,  1.5825, -0.5438,  0.2660,\n",
      "        -0.3472,  0.3667, -1.4810, -1.4797,  0.2789, -1.2285, -1.3081, -1.9305,\n",
      "         2.0595,  1.0548, -1.0194,  0.6544,  1.7655,  1.6903, -1.1825, -0.6807,\n",
      "        -1.5721, -1.0120,  1.3798,  0.9901,  3.3202,  2.6057, -0.2682,  0.4087,\n",
      "        -0.0751,  1.4298,  0.7328, -0.5683,  1.1924,  0.4600,  2.7206,  0.5908,\n",
      "        -0.4468,  0.5231,  0.9235,  0.1345, -2.3082, -0.8481, -1.5328, -1.4315,\n",
      "        -1.7530, -0.6548,  1.5989, -3.1568,  0.1215, -0.2737, -1.6184, -0.1060,\n",
      "         1.5683,  0.6983, -3.3968, -1.4742,  3.0821,  0.9807, -0.7706, -2.0512,\n",
      "        -0.6371,  1.6223,  0.9517, -0.5630, -0.2202, -2.7865,  2.9206, -2.1204,\n",
      "         0.3583, -0.2072,  0.6396,  0.9509, -0.7005, -0.6255, -0.2610,  1.5482,\n",
      "        -1.6500,  0.6422,  0.1149, -0.3115,  3.4342,  0.0142,  0.8490, -0.0243,\n",
      "        -0.2890,  1.7310,  1.2901,  0.5551,  2.7569,  2.3231, -3.6894,  2.2332,\n",
      "        -1.8910,  3.1075, -0.0079,  2.3227, -0.5956,  0.7147,  0.0502,  0.7127,\n",
      "        -1.7479,  0.1784, -1.6680, -0.3853, -4.2361,  0.6391,  0.0167, -1.6278])\n"
     ]
    }
   ],
   "source": [
    "print(model.gru.bN_u.runningMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e32b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "\n",
    "def tokenize(text):\n",
    "    if len(text) < N:\n",
    "        text = \"a\" * (N-len(text)) + text\n",
    "    out = torch.zeros(N, dtype=torch.long)\n",
    "    for i, c in enumerate(text):\n",
    "        out[i] = chars_to_int[c]\n",
    "\n",
    "    return out.reshape(1, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be475b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_char(tokens):\n",
    "    logits = model.forward(tokens, train=False)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    generated = torch.multinomial(probs, 1).item()\n",
    "    new_char = int_to_chars[generated]\n",
    "    return generated, new_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec5dd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(text, num):\n",
    "    tokens = tokenize(text)\n",
    "    for i in range(num):\n",
    "        token, new_char = generate_char(tokens)\n",
    "        text += new_char\n",
    "        tokens = torch.roll(tokens, -1, 1)\n",
    "        tokens[0][-1] = token\n",
    "\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "766672fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the thing that i hate is n't maching   \n",
      " the eria problemsdow market \n",
      " the\n"
     ]
    }
   ],
   "source": [
    "generate_text(\"the thing that i hate is\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bf8bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(\"../data/X_test\", \"rb\") as file:\n",
    "    seq = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bcf76b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" n't black monday \\n but while \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = seq[10]\n",
    "text = \"\"\n",
    "\n",
    "for c in line:\n",
    "    text += int_to_chars[c]\n",
    "\n",
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
